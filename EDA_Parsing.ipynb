{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forms:\n",
    "    10-K\n",
    "    10-Q\n",
    "    8-K\n",
    "    Proxy Statement\n",
    "    Forms 3, 4, 5\n",
    "    Schedulem13D\n",
    "    144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10-K:\n",
    "    NLP:\n",
    "        Business?\n",
    "        Risk Factors\n",
    "        Unresolved Staff Comments\n",
    "        Properties\n",
    "        Legal Proceedings\n",
    "        Mine Safety Disclosures\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get txt document from SEC website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlText = r\"https://www.sec.gov/Archives/edgar/data/1318605/000119312511054847/0001193125-11-054847.txt\"\n",
    "\n",
    "\n",
    "\n",
    "#get response\n",
    "response = requests.get(htmlText)\n",
    "\n",
    "# parse response\n",
    "soup = BeautifulSoup(response.content, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Ç'\n",
      "'Ç'\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "print('%r' % normalize('NFD', u'\\u00C7'))  # decompose: convert Ç to \"C + ̧\"\n",
    "print('%r' % normalize('NFC', u'C\\u0327')) # compose: convert \"C + ̧\" to Ç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Important Text Positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Business \n",
    "\n",
    "Risk Factors\n",
    "Unresolved Staff Comments\n",
    "Properties\n",
    "Legal Proceedings\n",
    "Reserved  \n",
    "\n",
    "Market for Registrant’s Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities \n",
    "Selected Financial Data\n",
    "Management’s Discussion and Analysis of Financial Condition and Results of Operations\n",
    "Quantitative and Qualitative Disclosures About Market Risk\n",
    "Financial Statements and Supplementary Data\n",
    "Changes in and Disagreements with Accountants on Accounting and Financial Disclosure\n",
    "Controls and Procedures \n",
    "Other Information\n",
    "\n",
    "Directors, Executive Officers and Corporate Governance\n",
    "Executive Compensation\n",
    "Security Ownership of Certain Beneficial Owners and Management and Related Stockholder Matters\n",
    "Certain Relationships and Related Transactions, and Director Independence\n",
    "Principal Accountant Fees and Services\n",
    "\n",
    "Exhibits and Financial Statement Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ç', '\\xa0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u'\\u00C7', u'\\xa0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_windows_1252_characters(restore_string):\n",
    "    \"\"\"\n",
    "        Replace C1 control characters in the Unicode string s by the\n",
    "        characters at the corresponding code points in Windows-1252,\n",
    "        where possible.\n",
    "    \"\"\"\n",
    "\n",
    "    def to_windows_1252(match):\n",
    "        try:\n",
    "            return bytes([ord(match.group(0))]).decode('windows-1252')\n",
    "        except UnicodeDecodeError:\n",
    "            # No character at the corresponding code point: remove it.\n",
    "            return ''\n",
    "        \n",
    "    return re.sub(r'[\\u0080-\\u0099]', to_windows_1252, restore_string)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def remove_newlines(string):\n",
    "#     # \\p, \\xa0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a master dictionary to house all filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new dict to house all filings\n",
    "master_filings_dict = {}\n",
    "\n",
    "#define a new key for each filing\n",
    "accession_number = '0001104659-04-027382'\n",
    "\n",
    "#add key to dict and add new level\n",
    "master_filings_dict[accession_number] = {} \n",
    "\n",
    "#add next levels\n",
    "master_filings_dict[accession_number]['sec_header_content'] = {}\n",
    "master_filings_dict[accession_number]['filing_documents'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting SEC header tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sec-header>0001193125-11-054847.hdr.sgml : 20110303\n",
       "<acceptance-datetime>20110303144736\n",
       "ACCESSION NUMBER:\t\t0001193125-11-054847\n",
       "CONFORMED SUBMISSION TYPE:\t10-K\n",
       "PUBLIC DOCUMENT COUNT:\t\t8\n",
       "CONFORMED PERIOD OF REPORT:\t20101231\n",
       "FILED AS OF DATE:\t\t20110303\n",
       "DATE AS OF CHANGE:\t\t20110303\n",
       "\n",
       "FILER:\n",
       "\n",
       "\tCOMPANY DATA:\t\n",
       "\t\tCOMPANY CONFORMED NAME:\t\t\tTESLA MOTORS INC\n",
       "\t\tCENTRAL INDEX KEY:\t\t\t0001318605\n",
       "\t\tSTANDARD INDUSTRIAL CLASSIFICATION:\tMOTOR VEHICLES &amp; PASSENGER CAR BODIES [3711]\n",
       "\t\tIRS NUMBER:\t\t\t\t912197729\n",
       "\t\tSTATE OF INCORPORATION:\t\t\tDE\n",
       "\n",
       "\tFILING VALUES:\n",
       "\t\tFORM TYPE:\t\t10-K\n",
       "\t\tSEC ACT:\t\t1934 Act\n",
       "\t\tSEC FILE NUMBER:\t001-34756\n",
       "\t\tFILM NUMBER:\t\t11659731\n",
       "\n",
       "\tBUSINESS ADDRESS:\t\n",
       "\t\tSTREET 1:\t\t3500 DEER CREEK RD\n",
       "\t\tCITY:\t\t\tPALO ALTO\n",
       "\t\tSTATE:\t\t\tCA\n",
       "\t\tZIP:\t\t\t94070\n",
       "\t\tBUSINESS PHONE:\t\t650-681-5000\n",
       "\n",
       "\tMAIL ADDRESS:\t\n",
       "\t\tSTREET 1:\t\t3500 DEER CREEK RD\n",
       "\t\tCITY:\t\t\tPALO ALTO\n",
       "\t\tSTATE:\t\t\tCA\n",
       "\t\tZIP:\t\t\t94070\n",
       "</acceptance-datetime></sec-header>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab the sec header doc\n",
    "sec_header_tag = soup.find('sec-header')\n",
    "#store header info in dict\n",
    "master_filings_dict[accession_number]['sec_header_content']['sec_header_text'] = sec_header_tag\n",
    "sec_header_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sec-header>0001193125-11-054847.hdr.sgml : 20110303\n",
       "<acceptance-datetime>20110303144736\n",
       "ACCESSION NUMBER:\t\t0001193125-11-054847\n",
       "CONFORMED SUBMISSION TYPE:\t10-K\n",
       "PUBLIC DOCUMENT COUNT:\t\t8\n",
       "CONFORMED PERIOD OF REPORT:\t20101231\n",
       "FILED AS OF DATE:\t\t20110303\n",
       "DATE AS OF CHANGE:\t\t20110303\n",
       "\n",
       "FILER:\n",
       "\n",
       "\tCOMPANY DATA:\t\n",
       "\t\tCOMPANY CONFORMED NAME:\t\t\tTESLA MOTORS INC\n",
       "\t\tCENTRAL INDEX KEY:\t\t\t0001318605\n",
       "\t\tSTANDARD INDUSTRIAL CLASSIFICATION:\tMOTOR VEHICLES &amp; PASSENGER CAR BODIES [3711]\n",
       "\t\tIRS NUMBER:\t\t\t\t912197729\n",
       "\t\tSTATE OF INCORPORATION:\t\t\tDE\n",
       "\n",
       "\tFILING VALUES:\n",
       "\t\tFORM TYPE:\t\t10-K\n",
       "\t\tSEC ACT:\t\t1934 Act\n",
       "\t\tSEC FILE NUMBER:\t001-34756\n",
       "\t\tFILM NUMBER:\t\t11659731\n",
       "\n",
       "\tBUSINESS ADDRESS:\t\n",
       "\t\tSTREET 1:\t\t3500 DEER CREEK RD\n",
       "\t\tCITY:\t\t\tPALO ALTO\n",
       "\t\tSTATE:\t\t\tCA\n",
       "\t\tZIP:\t\t\t94070\n",
       "\t\tBUSINESS PHONE:\t\t650-681-5000\n",
       "\n",
       "\tMAIL ADDRESS:\t\n",
       "\t\tSTREET 1:\t\t3500 DEER CREEK RD\n",
       "\t\tCITY:\t\t\tPALO ALTO\n",
       "\t\tSTATE:\t\t\tCA\n",
       "\t\tZIP:\t\t\t94070\n",
       "</acceptance-datetime></sec-header>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('sec-header')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "The document 10-K was parsed.\n",
      "There was 150 thematic breaks(s) found.\n",
      "--------------------------------------------------------------------------------\n",
      "The document EX-10.47 was parsed.\n",
      "There was 26 thematic breaks(s) found.\n",
      "--------------------------------------------------------------------------------\n",
      "The document EX-21.1 was parsed.\n",
      "There was 0 thematic breaks(s) found.\n",
      "--------------------------------------------------------------------------------\n",
      "The document EX-23.1 was parsed.\n",
      "There was 0 thematic breaks(s) found.\n",
      "--------------------------------------------------------------------------------\n",
      "The document EX-31.1 was parsed.\n",
      "There was 0 thematic breaks(s) found.\n",
      "--------------------------------------------------------------------------------\n",
      "The document EX-31.2 was parsed.\n",
      "There was 0 thematic breaks(s) found.\n",
      "--------------------------------------------------------------------------------\n",
      "The document EX-32.1 was parsed.\n",
      "There was 0 thematic breaks(s) found.\n",
      "--------------------------------------------------------------------------------\n",
      "The document GRAPHIC was parsed.\n",
      "There was 0 thematic breaks(s) found.\n",
      "--------------------------------------------------------------------------------\n",
      "All the documents for filing 0001104659-04-027382 were parsed and stored.\n"
     ]
    }
   ],
   "source": [
    "#initialize master dict\n",
    "master_document_dict = {}\n",
    "\n",
    "#loop through each doc in the filing\n",
    "for filing_document in soup.find_all('document'):\n",
    "    \n",
    "    #define document id\n",
    "    document_id = filing_document.type.find(text=True, recursive=False).strip()\n",
    "    \n",
    "    #document sequence\n",
    "    document_sequence = filing_document.sequence.find(text=True, recursive=False).strip()\n",
    "    \n",
    "    #document filename\n",
    "    document_filename = filing_document.filename.find(text=True, recursive=False).strip()\n",
    "    \n",
    "    #document description\n",
    "    document_description = filing_document.description.find(text=True, recursive=False).strip()\n",
    "    \n",
    "    #insert the key\n",
    "    master_document_dict[document_id] = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    master_document_dict[document_id]['document_sequence'] = document_sequence\n",
    "    master_document_dict[document_id]['document_filename'] = document_filename\n",
    "    master_document_dict[document_id]['document_description'] = document_description\n",
    "    \n",
    "    #add document content\n",
    "    master_document_dict[document_id]['document_code'] = filing_document.extract()\n",
    "    \n",
    "    #get all text\n",
    "    filing_doc_text = filing_document.find('text').extract()\n",
    "    master_document_dict[document_id]['filing_doc_text'] = filing_doc_text\n",
    "    \n",
    "    #get thematic breaks\n",
    "    thematic_breaks = filing_doc_text.find_all('hr',{'width':'100%'})\n",
    "    \n",
    "    #convert all thematic breaks to string\n",
    "    all_thematic_breaks = [str(thematic_break) for thematic_break in thematic_breaks]\n",
    "    \n",
    "    #prep the document text for splitting - convert to string\n",
    "    filing_doc_string = str(filing_doc_text)\n",
    "    \n",
    "    #if there are thematic breaks\n",
    "    if len(all_thematic_breaks) > 0:\n",
    "        \n",
    "        #defing the regex delimeter pattern\n",
    "        regex_delimiter_pattern = '|'.join(map(re.escape, all_thematic_breaks))\n",
    "        \n",
    "        #split doc on each break\n",
    "        split_filing_string = re.split(regex_delimiter_pattern, filing_doc_string)\n",
    "        \n",
    "        #store doc\n",
    "        master_document_dict[document_id]['pages_code'] = split_filing_string\n",
    "        \n",
    "        \n",
    "        \n",
    "    # handle the case where there are no thematic breaks.\n",
    "    elif len(all_thematic_breaks) == 0:\n",
    "\n",
    "        # handles so it will display correctly.\n",
    "        split_filing_string = all_thematic_breaks\n",
    "        \n",
    "        # store the document as is, since there are no thematic breaks. In other words, no splitting.\n",
    "        master_document_dict[document_id]['pages_code'] = [filing_doc_string]\n",
    "    \n",
    "\n",
    "    # display some information to the user.\n",
    "    print('-'*80)\n",
    "    print('The document {} was parsed.'.format(document_id))\n",
    "#     print('There was {} page(s) found.'.format(len(all_page_numbers)))\n",
    "    print('There was {} thematic breaks(s) found.'.format(len(all_thematic_breaks)))\n",
    "    \n",
    "\n",
    "# store the documents in the master_filing_dictionary.\n",
    "master_filings_dict[accession_number]['filing_documents'] = master_document_dict\n",
    "\n",
    "print('-'*80)\n",
    "print('All the documents for filing {} were parsed and stored.'.format(accession_number))\n",
    "\n",
    "\n",
    "# master_document_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-K\n",
      "EX-10.47\n",
      "EX-21.1\n",
      "EX-23.1\n",
      "EX-31.1\n",
      "EX-31.2\n",
      "EX-32.1\n",
      "GRAPHIC\n"
     ]
    }
   ],
   "source": [
    "for x in master_document_dict:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16375"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# master_document_dict['10-K']['pages_code']\n",
    "str(master_document_dict['10-K']['filing_doc_text']).find('Risk Factors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_document_dict['10-K']['pages_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_string = restore_windows_1252_characters(master_document_dict['10-K']['pages_code'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_string.find('Risk Factors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'whether'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_string[7547:7554]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we'll break up specifically 10-K Documents\n",
    "\n",
    "### Split up into Parts 1 - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Business \n",
    "\n",
    "Risk Factors\n",
    "Unresolved Staff Comments\n",
    "Properties\n",
    "Legal Proceedings\n",
    "Reserved  \n",
    "\n",
    "Market for Registrant’s Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities \n",
    "Selected Financial Data\n",
    "Management’s Discussion and Analysis of Financial Condition and Results of Operations\n",
    "Quantitative and Qualitative Disclosures About Market Risk\n",
    "Financial Statements and Supplementary Data\n",
    "Changes in and Disagreements with Accountants on Accounting and Financial Disclosure\n",
    "Controls and Procedures \n",
    "Other Information\n",
    "\n",
    "Directors, Executive Officers and Corporate Governance\n",
    "Executive Compensation\n",
    "Security Ownership of Certain Beneficial Owners and Management and Related Stockholder Matters\n",
    "Certain Relationships and Related Transactions, and Director Independence\n",
    "Principal Accountant Fees and Services\n",
    "\n",
    "Exhibits and Financial Statement Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
