{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1:\n",
    "\n",
    "### Extract 10-K text and semgment into sections designated by table of contents for a specific filing document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_tenk_text_dict = get_text_dict(r\"https://www.sec.gov/Archives/edgar/data/1318605/000119312511054847/0001193125-11-054847.txt\", '10-K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Evaluation of Disclosure Controls and Procedures Our management, with the participation of our chief executive officer and chief financial officer, evaluated the effectiveness of our disclosure controls and procedures as of December 31, 2010. The term disclosure controls and procedures, as defined in Rules 13a-15(e) and 15d-15(e) under the Exchange Act, means controls and other procedures of a company that are designed to ensure that information required to be disclosed by a company in the reports that it files or submits under the Exchange Act is recorded, processed, summarized and reported, within the time periods specified in the SECs rules and forms. Disclosure controls and procedures include, without limitation, controls and procedures designed to ensure that information required to be disclosed by a company in the reports that it files or submits under the Exchange Act is accumulated and communicated to the companys management, including its principal executive and principal financial officers, as appropriate to allow timely decisions regarding required disclosure. Based on the evaluation of our disclosure controls and procedures as of December 31, 2010, our chief executive officer and chief financial officer concluded that, as of such date, our disclosure controls and procedures were effective at the reasonable assurance level. Management recognizes that any controls and procedures, no matter how well designed and operated, can provide only reasonable assurance of achieving their objectives and management necessarily applies its judgment in evaluating the cost-benefit relationship of possible controls and procedures. Managements Annual Report on Internal Control Over Financial Reporting This Annual Report on Form 10-K does not include a report of managements assessment regarding internal control over financial reporting or an attestation report of our registered public accounting firm as permitted in this transition period under the rules of the SEC for newly public companies. Changes in Internal Control over Financial Reporting There were no changes in our internal control over financial reporting identified in managements evaluation pursuant to Rules 13a-15(d) or 15d-15(d) of the Exchange Act during the quarter ended December 31, 2010 that materially affected, or are reasonably likely to materially affect, our internal control over financial reporting. ITEM 9B.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_tenk_text_dict['CONTROLS AND PROCEDURES ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We currently have no structure in place to parse an 8-K. Please try again later!\n"
     ]
    }
   ],
   "source": [
    "testing_eightk = get_text_dict(r'https://www.sec.gov/Archives/edgar/data/1318605/000156459021012981/0001564590-21-012981.txt', '8-K')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have text organized into these sections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in parsed_tenk_text_dict.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We also want to do the same with 10-Q forms for quarterly reports. \n",
    "### Part of the analysis will be comparing 10-Qs with past 10-Qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "\n",
    "Will compare the cosine similarity from previous doc sections to current sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing nlp pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    return only_ascii.decode()\n",
    "\n",
    "input_string = remove_accents(parsed_tenk_text_dict['CONTROLS AND PROCEDURES '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sent_tokens = sent_tokenize(input_string)\n",
    "\n",
    "sent_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk.tokenize.word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = [word_tokenize(sent) for sent in sent_tokens]\n",
    "\n",
    "list(enumerate(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make lowercase\n",
    "\n",
    "import string\n",
    "\n",
    "tokens_lower = [[word.lower() for word in sent]\n",
    "                 for sent in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter stopwords and punctuation\n",
    "\n",
    "### will need to go back and create custom stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_ = set(stopwords.words('english'))\n",
    "punctuation_ = set(string.punctuation)\n",
    "print(\"--- punctuation: {}\".format(string.punctuation))\n",
    "\n",
    "def filter_tokens(sent):\n",
    "    return([w for w in sent if not w in stopwords_ and not w in punctuation_])\n",
    "\n",
    "tokens_filtered = list(map(filter_tokens, tokens_lower))\n",
    "\n",
    "for sent in tokens_filtered:\n",
    "    print(\"--- sentence tokens: {}\".format(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "sentence_number = 0\n",
    "\n",
    "stemmer_porter = PorterStemmer()\n",
    "tokens_stemporter = [list(map(stemmer_porter.stem, sent)) for sent in tokens_filtered]\n",
    "print(\"--- sentence tokens (porter): {}\".format(tokens_stemporter[sentence_number]))\n",
    "\n",
    "stemmer_snowball = SnowballStemmer('english')\n",
    "tokens_stemsnowball = [list(map(stemmer_snowball.stem, sent)) for sent in tokens_filtered]\n",
    "print(\"--- sentence tokens (snowball): {}\".format(tokens_stemsnowball[sentence_number]))\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokens_lemmatize = [list(map(lemmatizer.lemmatize, sent)) for sent in tokens_filtered]\n",
    "print(\"--- sentence tokens (lemmatize): {}\".format(tokens_lemmatize[sentence_number]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
